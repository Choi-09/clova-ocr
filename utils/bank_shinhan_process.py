# import csv
# import json
# import time
# import uuid
#
# import requests
# import re
#
# api_url = 
# secret_key = 
# image_file_path = 'C:\\Study\\law-vo\\'
# image_file_name = 'ì‹ í•œì€í–‰-ê±°ë˜ë‚´ì—­'
# file_format = '.pdf'
# image_file = image_file_path + image_file_name + file_format
# # OCR ìš”ì²­
# request_json = {
#     'images': [
#         {
#             'format': 'pdf',
#             'name': 'demo'
#         }
#     ],
#     'requestId': str(uuid.uuid4()),
#     'version': 'V2',
#     'timestamp': int(round(time.time() * 1000))
# }
#
# payload = {'message': json.dumps(request_json).encode('UTF-8')}
# files = [('file', open(image_file,'rb'))]
# headers = {'X-OCR-SECRET': secret_key}
# response = requests.post(api_url, headers=headers, data=payload, files=files)
# result = json.loads(response.text)
# # print("result: ", result)
#
# # ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ
# fields = []
# # detail_field = []
# print(json.dumps(result['images'], indent=2, ensure_ascii=False))
#
# for image in result['images']:
#     if image.get('fields'):
#         fields.extend(image['fields'])
#     elif 'title' in image and 'subFields' in image['title']:
#         fields.extend(image['title']['subFields'])
#         print("fields: ", fields)
#     else:
#         pass
#
# basic_info_text = ' '.join(field.get('inferText', '') for field in fields)
# print("basic_info_text: ", basic_info_text)
#
# # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ í•¨ìˆ˜
# def extract_basic_info(text):
#     info = {}
#     patterns = {
#         'ê³„ì¢Œë²ˆí˜¸': r'ê³„ì¢Œë²ˆí˜¸[:\s]*([\d\-]+)',
#         'ì˜ˆê¸ˆì£¼': r'ì˜ˆê¸ˆì£¼ ì„±ëª…[:\s]*([^\s]+)',
#         'ìƒí’ˆëª…': r'ìƒí’ˆëª…[:\s]*([^\s]+)',
#         'ì¡°íšŒê¸°ê°„': r'ì¡°íšŒê¸°ê°„[:\s]*([\d\-]+)\s* \s*([\d\-]+)',
#         'ì—…ë¬´êµ¬ë¶„': r'ì—…ë¬´êµ¬ë¶„ 1:[:\s]*([\d:ê°€-í£]+)'
#     }
#     for key, pattern in patterns.items():
#         m = re.search(pattern, text)
#         if m:
#             if key == 'ì¡°íšŒê¸°ê°„':
#                 info[key] = f"{m.group(1)} ~ {m.group(2)}"
#             else:
#                 info[key] = m.group(1)
#         else:
#             info[key] = ''
#     return info
#
# basic_info = extract_basic_info(basic_info_text)
#
# print("basic_info: ", basic_info)
#
# # ê±°ë˜ë‚´ì—­ ì¶”ì¶œ
# def extract_transaction_table_by_position(fields, y_threshold=5):
#     # 1. í•„ë“œ ì •ë¦¬ (í…ìŠ¤íŠ¸ + ì¤‘ì‹¬ ì¢Œí‘œ ì¶”ì¶œ)
#     items = []
#     for field in fields:
#         text = field.get('inferText', '').strip()
#         vertices = field.get('boundingPoly', {}).get('vertices', [])
#         if not text or not vertices:
#             continue
#         # x = sum(v.get('x', 0) for v in vertices) / len(vertices)
#         x = min(v.get('x', 0) for v in vertices)
#         y = sum(v.get('y', 0) for v in vertices) / len(vertices)
#         items.append({'text': text, 'x': int(x), 'y': int(y)})
#
#     # 2. y ê¸°ì¤€ ì •ë ¬ ë° í–‰ ê·¸ë£¹í™”
#     items.sort(key=lambda x: x['y'])
#     rows = []
#     current_row = []
#     prev_y = None
#
#     for item in items:
#         if prev_y is None or abs(item['y'] - prev_y) <= y_threshold:
#             current_row.append(item)
#         else:
#             rows.append(current_row)
#             current_row = [item]
#         prev_y = item['y']
#     if current_row:
#         rows.append(current_row)
#
#     # 3. ì˜¬ë°”ë¥¸ í—¤ë” í–‰ íƒìƒ‰
#     header_row = None
#     header_y = None
#     for row in rows:
#         texts = [item['text'] for item in row]
#         joined_text = ''.join(texts)
#         if all(key in joined_text for key in ['ê±°ë˜ì¼ì', 'ë‚´ìš©', 'ì°¾ìœ¼ì‹ ê¸ˆì•¡', 'ë§¡ê¸°ì‹ ê¸ˆì•¡']):
#             header_row = sorted(row, key=lambda x: x['x'])
#             header_y = sum(item['y'] for item in row) / len(row)
#             break
#     if not header_row:
#         raise ValueError("í—¤ë” í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
#
#     # 4. í—¤ë” ë³‘í•© ì²˜ë¦¬ ë° ìœ„ì¹˜ ì„¤ì •
#     merged_header = []
#     merged_positions = []
#     i = 0
#     while i < len(header_row):
#         this_text = header_row[i]['text']
#         if i + 1 < len(header_row):
#             next_text = header_row[i + 1]['text']
#             merged = this_text + next_text
#             if merged in ['ë¹„ê³ ', 'ì”ì•¡']:
#                 merged_header.append(merged)
#                 merged_positions.append((header_row[i]['x'] + header_row[i + 1]['x']) // 2)
#                 i += 2
#                 continue
#         merged_header.append(this_text)
#         merged_positions.append(header_row[i]['x'])
#         i += 1
#
#     # 5. x ìœ„ì¹˜ ê¸°ì¤€ ê²½ê³„ ê³„ì‚°
#     correction = 10
#     x_ranges = []
#     for i in range(len(merged_positions)):
#         if i == 0:
#             left = -float('inf')
#         else:
#             left = (merged_positions[i - 1] + merged_positions[i]) // 2
#         if i == len(merged_positions) - 1:
#             right = float('inf')
#         else:
#             right = (merged_positions[i] + merged_positions[i + 1]) // 2
#         x_ranges.append((left - correction, right + correction))
#
#     # 6. í—¤ë” ì•„ë˜ í–‰ í•„í„°ë§ ë° ì •ë ¬
#     aligned_rows = []
#     for row in rows:
#         # í—¤ë”ë³´ë‹¤ ìœ„ì— ìˆëŠ” ê²½ìš° ë¬´ì‹œ
#         avg_y = sum(item['y'] for item in row) / len(row)
#         if avg_y <= header_y:
#             continue
#
#         # ê±°ë˜ì¼ì íŒ¨í„´ í™•ì¸
#         row_texts = [item['text'] for item in row]
#         if not any(re.match(r'\d{4}-\d{2}-\d{2}', text) for text in row_texts):
#             continue
#
#         aligned = [' '] * len(merged_positions)
#         for item in row:
#             x = item['x']
#             for idx, (left, right) in enumerate(x_ranges):
#                 if left <= x < right:
#                     aligned[idx] = item['text']
#                     break
#         aligned_rows.append(aligned)
#
#     return merged_header, aligned_rows
#
#
#
# header, rows = extract_transaction_table_by_position(fields)
# print("header:" , header,  "rows: ", rows)
#
# def replace_W_before_number(text):
#     return re.sub(r'W(?=\d)', r'\\', text)
#
# csv_file_name = f'{image_file_name}.csv'
# with open(csv_file_name, mode='w', newline='', encoding='utf-8-sig') as f:
#     writer = csv.writer(f)
#
#     # ê¸°ë³¸ ì •ë³´
#     writer.writerow(['[ê¸°ë³¸ ì •ë³´]'])
#     for key, value in basic_info.items():
#         writer.writerow([key, value])
#
#     writer.writerow([])
#     writer.writerow(['[ê±°ë˜ ë‚´ì—­]'])
#
#     # ê±°ë˜ ë‚´ì—­
#     writer.writerow(header)
#     for row in rows:
#         new_row = [replace_W_before_number(cell) for cell in row]
#
#         if isinstance(new_row, list):
#             writer.writerow(new_row)
#         elif isinstance(new_row, str):
#             writer.writerow(new_row.split(','))
#         else:
#             print("Unexpected row format:", new_row)


import os
import uuid
import time
import re
import requests
import json
from PyPDF2 import PdfReader, PdfWriter
from openpyxl import Workbook
from dotenv import load_dotenv


load_dotenv() 

# ê¸°ë³¸ ì„¤ì •
API_URL = os.getenv("API_URL")
print("API_URL: ", API_URL)
SECRET_KEY = os.getenv("SECRET_KEY")

# PDF -> ë‹¨ì¼ í˜ì´ì§€ PDFë¡œ ë¶„í• 
def split_pdf_pages(pdf_path, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    reader = PdfReader(pdf_path)
    paths = []

    base_filename = os.path.splitext(os.path.basename(pdf_path))[0]

    for i, page in enumerate(reader.pages):
        path = os.path.join(output_dir, f"{base_filename}-{i+1}.pdf")
        with open(path, "wb") as f:
            writer = PdfWriter()
            writer.add_page(page)
            writer.write(f)
        paths.append(path)
    return paths

# OCR ìš”ì²­
def call_ocr_api(pdf_path):
    try:
        with open(pdf_path, 'rb') as file:
            payload = {
                'message': json.dumps({
                    'images': [{'format': 'pdf', 'name': 'demo'}],
                    'requestId': str(uuid.uuid4()),
                    'version': 'V2',
                    'timestamp': int(time.time() * 1000)
                }).encode('UTF-8')
            }
            files = [('file', file)]
            headers = {'X-OCR-SECRET': SECRET_KEY}
            response = requests.post(API_URL, headers=headers, data=payload, files=files)
            return response.json()
    except Exception as e:
        print(f"[ERROR] OCR API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None

# ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
def extract_basic_info(text):
    patterns = {
        'ê³„ì¢Œë²ˆí˜¸': r'ê³„ì¢Œë²ˆí˜¸[:\s]*([\d\-]+)',
        'ì˜ˆê¸ˆì£¼': r'ì˜ˆê¸ˆì£¼ ì„±ëª…[:\s]*([^\s]+)',
        'ìƒí’ˆëª…': r'ìƒí’ˆëª…[:\s]*([^\s]+)',
        'ì¡°íšŒê¸°ê°„': r'ì¡°íšŒê¸°ê°„[:\s]*([\d\-]+)\s* \s*([\d\-]+)',
        'ì—…ë¬´êµ¬ë¶„': r'ì—…ë¬´êµ¬ë¶„ 1:[:\s]*([\d:ê°€-í£]+)'
    }
    info = {}
    for key, pattern in patterns.items():
        match = re.search(pattern, text)
        if key == 'ì¡°íšŒê¸°ê°„' and match:
            info[key] = f"{match.group(1)} ~ {match.group(2)}"
        else:
            info[key] = match.group(1) if match else ''
    return info

# ê±°ë˜ë‚´ì—­ ì¶”ì¶œ
def extract_transaction_table_by_position(fields, y_threshold=5):
    # 1. í•„ë“œ ì •ë¦¬ (í…ìŠ¤íŠ¸ + ì¤‘ì‹¬ ì¢Œí‘œ ì¶”ì¶œ)
    items = [
        {
            'text': f.get('inferText', '').strip(),
            'x': min(v.get('x', 0) for v in f.get('boundingPoly', {}).get('vertices', [])),
            'y': sum(v.get('y', 0) for v in f.get('boundingPoly', {}).get('vertices', [])) / 4
        }
        for f in fields if f.get('inferText') and f.get('boundingPoly')
    ]
    items.sort(key=lambda x: x['y'])

    # 2. y ê¸°ì¤€ ì •ë ¬ ë° í–‰ ê·¸ë£¹í™”
    rows, row, prev_y = [], [], None
    for item in items:
        if prev_y is None or abs(item['y'] - prev_y) <= y_threshold:
            row.append(item)
        else:
            rows.append(row)
            row = [item]
        prev_y = item['y']
    if row:
        rows.append(row)

    # 3. í—¤ë” ì°¾ê¸°
    for row in rows:
        joined_text = ''.join([item['text'] for item in row])
        if all(key in joined_text for key in ['ê±°ë˜ì¼ì', 'ë‚´ìš©', 'ì°¾ìœ¼ì‹ ê¸ˆì•¡', 'ë§¡ê¸°ì‹ ê¸ˆì•¡']):
            header_row = sorted(row, key=lambda x: x['x'])
            header_y = sum(item['y'] for item in row) / len(row)
            break
    else:
        raise ValueError("í—¤ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 4. í—¤ë” ë³‘í•© ì²˜ë¦¬ ë° ìœ„ì¹˜ ì„¤ì •
    merged_header, merged_x = [], []
    i = 0
    while i < len(header_row):
        curr = header_row[i]['text']
        if i + 1 < len(header_row):
            next_text = header_row[i + 1]['text']
            if curr + next_text in ['ë¹„ê³ ', 'ì”ì•¡']:
                merged_header.append(curr+ next_text)
                merged_x.append((header_row[i]['x'] + header_row[i + 1]['x']) // 2)
                i += 2
                continue
        merged_header.append(curr)
        merged_x.append(header_row[i]['x'])
        i += 1

    # 5. x ìœ„ì¹˜ ê¸°ì¤€ ê²½ê³„ ê³„ì‚°
    correction = 10
    x_ranges = []
    for i in range(len(merged_x)):
        left = (merged_x[i - 1] + merged_x[i]) // 2 if i > 0 else -float('inf')
        right = (merged_x[i] + merged_x[i + 1]) // 2 if i < len(merged_x) - 1 else float('inf')
        x_ranges.append((left - correction, right + correction))

    # 6. ê±°ë˜ë‚´ì—­ í–‰ ì •ë ¬
    aligned_rows = []
    for row in rows:
        if sum(i['y'] for i in row) / len(row) <= header_y:
            continue
        if not any(re.match(r'\d{4}-\d{2}-\d{2}', i['text']) for i in row):
            continue
        aligned = [''] * len(merged_x)

        for item in row:
            for idx, (left, right) in enumerate(x_ranges):
                if left <= item['x'] < right:
                    aligned[idx] = item['text']
                    break
        aligned_rows.append(aligned)
    return merged_header, aligned_rows

# ìˆ«ì ì• ë¬¸ì ì›í™” ê¸°í˜¸ë¡œ ë°”ê¾¸ê¸°
def replace_W_before_number(text):
    return re.sub(r'[W\\](?=\d)', 'â‚©', text)

# Excel ì €ì¥
def save_to_excel(wb, sheet_name, basic_info, header, rows):
    ws = wb.create_sheet(title=sheet_name)
    ws.append(["[ê¸°ë³¸ ì •ë³´]"])
    for key, value in basic_info.items():
        ws.append([key, value])
    ws.append([])
    ws.append([f"[{sheet_name} - ê±°ë˜ ë‚´ì—­]"])
    ws.append(header)
    for row in rows:
        ws.append([replace_W_before_number(cell) for cell in row])

# ì‹¤í–‰
def process_pdf_and_ocr(input_pdf_path, update_progress_callback=None):
    temp_dir = os.path.join('temp_split', os.path.splitext(os.path.basename(input_pdf_path))[0])

    pdf_pages = split_pdf_pages(input_pdf_path, temp_dir)
    total_pages = len(pdf_pages)

    wb = Workbook()
    wb.remove(wb.active)

    for idx, page_pdf in enumerate(pdf_pages):
        print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: í˜ì´ì§€ {idx + 1}")
        result = call_ocr_api(page_pdf)
        if not result or 'images' not in result:
            print(f"[âš ï¸] í˜ì´ì§€ {idx + 1} OCR ì‹¤íŒ¨")
            if update_progress_callback:
                update_progress_callback((idx + 1) / total_pages * 100)
            continue

        images = result['images']
        total_images = len(images)

        fields = []
        for img_idx, image in enumerate(images):
            if image.get('fields'):
                fields.extend(image['fields'])
            elif 'title' in image and 'subFields' in image['title']:
                fields.extend(image['title']['subFields'])

            if update_progress_callback:
                progress = (idx + (img_idx + 1) / total_images) / total_pages
                update_progress_callback(int(progress * 100))

        text = ' '.join(field.get('inferText', '') for field in fields)
        basic_info = extract_basic_info(text)

        try:
            header, rows = extract_transaction_table_by_position(fields)
            save_to_excel(wb, f"í˜ì´ì§€ {idx + 1}", basic_info, header, rows)
        except Exception as e:
            print(f"[âš ï¸] í˜ì´ì§€ {idx + 1} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")


    return wb
