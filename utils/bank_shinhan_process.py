import os
import uuid
import time
import re
import requests
import json
from PyPDF2 import PdfReader, PdfWriter
from openpyxl import Workbook
from dotenv import load_dotenv


load_dotenv()

# ê¸°ë³¸ ì„¤ì •
API_URL = os.getenv("API_URL")
SECRET_KEY = os.getenv("SECRET_KEY")

# PDF -> ë‹¨ì¼ í˜ì´ì§€ PDFë¡œ ë¶„í• 
def split_pdf_pages(pdf_path, output_dir):
    """
    PDF íŒŒì¼ì„ í˜ì´ì§€ë³„ë¡œ ë¶„í• í•˜ì—¬ ê°œë³„ PDF íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        pdf_path (str): ì›ë³¸ PDF íŒŒì¼ì˜ ê²½ë¡œ.
        output_dir (str): ë¶„í• ëœ PDF íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬.

    Returns:
        list: ë¶„í• ëœ ê° í˜ì´ì§€ PDF íŒŒì¼ì˜ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸.
    """
    os.makedirs(output_dir, exist_ok=True)
    reader = PdfReader(pdf_path)
    paths = []

    base_filename = os.path.splitext(os.path.basename(pdf_path))[0]

    for i, page in enumerate(reader.pages):
        path = os.path.join(output_dir, f"{base_filename}-{i+1}.pdf")
        with open(path, "wb") as f:
            writer = PdfWriter()
            writer.add_page(page)
            writer.write(f)
        paths.append(path)
    return paths

# OCR ìš”ì²­
def call_ocr_api(pdf_path):
    """
    ë„¤ì´ë²„ CLOVA OCR APIë¥¼ í˜¸ì¶œí•˜ì—¬ PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        pdf_path (str): OCRì„ ìˆ˜í–‰í•  PDF íŒŒì¼ì˜ ê²½ë¡œ.

    Returns:
        dict: OCR API ì‘ë‹µ JSON. ì˜¤ë¥˜ ë°œìƒ ì‹œ None.
    """
    try:
        with open(pdf_path, 'rb') as file:
            payload = {
                'message': json.dumps({
                    'images': [{'format': 'pdf', 'name': 'demo'}],
                    'requestId': str(uuid.uuid4()),
                    'version': 'V2',
                    'timestamp': int(time.time() * 1000)
                }).encode('UTF-8')
            }
            files = [('file', file)]
            headers = {'X-OCR-SECRET': SECRET_KEY}
            response = requests.post(API_URL, headers=headers, data=payload, files=files)
            response.raise_for_status() # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ
            # print(response.json())
            return response.json()
    except requests.exceptions.RequestException as e:
        print(f"[ERROR] OCR API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None
    except Exception as e:
        print(f"[ERROR] OCR API ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
def extract_basic_info(text):
    patterns = {
        'ê³„ì¢Œë²ˆí˜¸': r'ê³„ì¢Œë²ˆí˜¸[:\s]*([\d\-]+)',
        'ì˜ˆê¸ˆì£¼': r'ì˜ˆê¸ˆì£¼ ì„±ëª…[:\s]*([^\s]+)',
        'ìƒí’ˆëª…': r'ìƒí’ˆëª…[:\s]*([^\s]+)',
        'ì¡°íšŒê¸°ê°„': r'ì¡°íšŒê¸°ê°„[:\s]*([\d\-]+)\s* \s*([\d\-]+)',
        'ì—…ë¬´êµ¬ë¶„': r'ì—…ë¬´êµ¬ë¶„ 1:[:\s]*([\d:ê°€-í£]+)'
    }
    info = {}
    for key, pattern in patterns.items():
        match = re.search(pattern, text)
        if key == 'ì¡°íšŒê¸°ê°„' and match:
            info[key] = f"{match.group(1)} ~ {match.group(2)}"
        else:
            info[key] = match.group(1) if match else ''
    return info

# ê±°ë˜ë‚´ì—­ ì¶”ì¶œ
def extract_transaction_table_by_position(fields, y_threshold=5):
    """
    OCR í•„ë“œ ë°ì´í„°ì—ì„œ ê±°ë˜ë‚´ì—­ í…Œì´ë¸”ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    í—¤ë”ëŠ” subFieldsì—ì„œ, ê±°ë˜ë‚´ì—­ì€ ì£¼ìš” inferText ë¸”ë¡ì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

    Args:
        fields (list): OCR APIì—ì„œ ë°˜í™˜ëœ ëª¨ë“  í•„ë“œ(í…ìŠ¤íŠ¸ ë° ë°”ìš´ë”© ë°•ìŠ¤) ë¦¬ìŠ¤íŠ¸.
        y_threshold (int): (ì´ í•¨ìˆ˜ì—ì„œëŠ” ì§ì ‘ ì‚¬ìš©ë˜ì§€ ì•Šì§€ë§Œ, ê¸°ì¡´ ì‹œê·¸ë‹ˆì²˜ ìœ ì§€ë¥¼ ìœ„í•´ ë‚¨ê²¨ë‘ )

    Returns:
        tuple: (í—¤ë” ë¦¬ìŠ¤íŠ¸, ê±°ë˜ë‚´ì—­ í–‰ ë¦¬ìŠ¤íŠ¸).
               ê° ê±°ë˜ë‚´ì—­ í–‰ì€ ì…€ ê°’ì˜ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    Raises:
        ValueError: í—¤ë” ì •ë³´ ë˜ëŠ” ì „ì²´ í…Œì´ë¸” í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°.
    """
    header_fields_from_subfields = []
    main_table_text_block_content = ""

    # fields ë¦¬ìŠ¤íŠ¸ì—ì„œ í—¤ë” subFieldsì™€ ë©”ì¸ í…Œì´ë¸” í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ì‹ë³„í•©ë‹ˆë‹¤.
    for field_item in fields:
        if 'subFields' in field_item and field_item['subFields']:
            header_fields_from_subfields.extend([
                {'text': sf['inferText'].strip(),
                 'x': min(v.get('x', 0) for v in sf.get('boundingPoly', {}).get('vertices', [])),
                 'y': sum(v.get('y', 0) for v in sf.get('boundingPoly', {}).get('vertices', [])) / 4}
                for sf in field_item['subFields'] if sf.get('inferText') and sf.get('boundingPoly')
            ])
        # ì—¬ëŸ¬ ì¤„ì„ í¬í•¨í•˜ê³  ê¸¸ì´ê°€ ê¸´ í•„ë“œëŠ” ì „ì²´ í…Œì´ë¸” í…ìŠ¤íŠ¸ ë¸”ë¡ìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
        # OCR ì‘ë‹µ ìƒ˜í”Œì— ë”°ë¥´ë©´ 'Field 01'ì´ ì´ ì—­í• ì„ í•©ë‹ˆë‹¤.
        if '\n' in field_item.get('inferText', '') and len(field_item.get('inferText', '').split('\n')) > 3:
            main_table_text_block_content = field_item['inferText']

    if not header_fields_from_subfields or not main_table_text_block_content:
        raise ValueError("OCR ì‘ë‹µì—ì„œ í—¤ë” ì •ë³´ ë˜ëŠ” ì „ì²´ í…Œì´ë¸” í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 1. í•„ë“œ ì •ë¦¬ (í…ìŠ¤íŠ¸ + ì¤‘ì‹¬ ì¢Œí‘œ ì¶”ì¶œ) - ì´ ë‹¨ê³„ëŠ” ì´ì œ header_fields_from_subfieldsì— ì§ì ‘ ì ìš©ë©ë‹ˆë‹¤.
    # header_fields_from_subfieldsëŠ” ì´ë¯¸ í•„ìš”í•œ 'text', 'x', 'y' ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

    # 2. y ê¸°ì¤€ ì •ë ¬ ë° í–‰ ê·¸ë£¹í™” - ì´ ë‹¨ê³„ëŠ” í—¤ë” ì‹ë³„ì—ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    # (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    items = sorted(header_fields_from_subfields, key=lambda x: x['y'])
    rows_for_header_detection, row, prev_y = [], [], None
    for item in items:
        if prev_y is None or abs(item['y'] - prev_y) <= y_threshold:
            row.append(item)
        else:
            rows_for_header_detection.append(row)
            row = [item]
        prev_y = item['y']
    if row:
        rows_for_header_detection.append(row)

        # 3. í—¤ë” ì°¾ê¸° (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    for row in rows_for_header_detection:
        joined_text = ''.join([item['text'] for item in row])
        if all(key in joined_text for key in ['ê±°ë˜ì¼ì', 'ë‚´ìš©', 'ì°¾ìœ¼ì‹ ê¸ˆì•¡', 'ë§¡ê¸°ì‹ ê¸ˆì•¡']):
            header_row = sorted(row, key=lambda x: x['x'])
            header_y = sum(item['y'] for item in row) / len(row)
            break
    else:
        raise ValueError("í—¤ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 4. í—¤ë” ë³‘í•© ì²˜ë¦¬ ë° ìœ„ì¹˜ ì„¤ì •
    merged_header, merged_x = [], []
    i = 0
    while i < len(header_row):
        curr = header_row[i]['text']
        if i + 1 < len(header_row):
            next_text = header_row[i + 1]['text']
            if curr + next_text in ['ë¹„ê³ ', 'ì”ì•¡']:
                merged_header.append(curr+ next_text)
                merged_x.append((header_row[i]['x'] + header_row[i + 1]['x']) // 2)
                i += 2
                continue
        merged_header.append(curr)
        merged_x.append(header_row[i]['x'])
        i += 1

    # 5. x ìœ„ì¹˜ ê¸°ì¤€ ê²½ê³„ ê³„ì‚° (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    column_boundaries = []
    if not merged_x: # í—¤ë”ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        return [], []

    for i in range(len(merged_x)):
        left = (merged_x[i - 1] + merged_x[i]) / 2 if i > 0 else -float('inf')
        right = (merged_x[i] + merged_x[i + 1]) / 2 if i < len(merged_x) - 1 else float('inf')
        column_boundaries.append((left, right))

    # 6. ê±°ë˜ë‚´ì—­ í–‰ ì •ë ¬
    aligned_rows = []
    lines = main_table_text_block_content.split('\n')

    # ì‹¤ì œ ë°ì´í„°ê°€ ì‹œì‘í•˜ëŠ” í–‰ ì°¾ê¸° (ë‚ ì§œ íŒ¨í„´ìœ¼ë¡œ ì‹ë³„)
    data_start_index = -1
    for i, line in enumerate(lines):
        # YYYY-MM-DD ë˜ëŠ” YY-MM-DD ë˜ëŠ” YYYY.MM.DD ë˜ëŠ” YY.MM.DD íŒ¨í„´
        if re.match(r'(\d{4}[-.]\d{2}[-.]\d{2}|\d{2}[-.]\d{2}[-.]\d{2})', line.strip()):
            data_start_index = i
            break

    if data_start_index == -1:
        print("[WARNING] ê±°ë˜ë‚´ì—­ ë°ì´í„° ì‹œì‘ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ í…ìŠ¤íŠ¸ ë¸”ë¡ì„ í™•ì¸í•˜ì„¸ìš”.")
        return merged_header, [] # ë°ì´í„° í–‰ì„ ì°¾ì§€ ëª»í•˜ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

    for line_str in lines[data_start_index:]:
        line_str = line_str.strip()
        if not line_str: # ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
            continue

        aligned_row = [''] * len(merged_header)

        parts = re.split(r'\s{2,}', line_str)

        # ë¶„ë¦¬ëœ ë¶€ë¶„ì„ í—¤ë” ì—´ì— ìˆœì°¨ì ìœ¼ë¡œ í• ë‹¹
        for p_idx, part in enumerate(parts):
            if p_idx < len(aligned_row):
                # ê¸°ì¡´ ë‚´ìš©ì´ ìˆìœ¼ë©´ ê³µë°±ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì¶”ê°€
                if aligned_row[p_idx]:
                    aligned_row[p_idx] += " " + part
                else:
                    aligned_row[p_idx] = part
            else:
                # ë¶„ë¦¬ëœ ë¶€ë¶„ì´ í—¤ë” ì—´ë³´ë‹¤ ë§ìœ¼ë©´ ë§ˆì§€ë§‰ ì—´ì— ì¶”ê°€ (ë³‘í•©)
                aligned_row[-1] += (" " + part) if aligned_row[-1] else part

        aligned_rows.append(aligned_row)

    return merged_header, aligned_rows

# ìˆ«ì ì• ë¬¸ì ì›í™” ê¸°í˜¸ë¡œ ë°”ê¾¸ê¸°
def replace_W_before_number(text):
    """
    í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ìˆ«ì ì•ì— ìˆëŠ” 'W' ë˜ëŠ” '\' ë¬¸ìë¥¼ 'â‚©' (ì›í™” ê¸°í˜¸)ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.

    Args:
        text (str): ì²˜ë¦¬í•  í…ìŠ¤íŠ¸.

    Returns:
        str: ì›í™” ê¸°í˜¸ë¡œ ëŒ€ì²´ëœ í…ìŠ¤íŠ¸.
    """
    return re.sub(r'[W\\](?=\d)', 'â‚©', text)

# Excel ì €ì¥
def save_to_excel(wb, sheet_name, basic_info, header, rows):
    """
    ì¶”ì¶œëœ ê¸°ë³¸ ì •ë³´ì™€ ê±°ë˜ë‚´ì—­ì„ Excel ì›Œí¬ë¶ì— ì‹œíŠ¸ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        wb (openpyxl.Workbook): ì €ì¥í•  Excel ì›Œí¬ë¶ ê°ì²´.
        sheet_name (str): ìƒì„±í•  ì‹œíŠ¸ì˜ ì´ë¦„.
        basic_info (dict): ê¸°ë³¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬.
        header (list): í…Œì´ë¸” í—¤ë” ë¦¬ìŠ¤íŠ¸.
        rows (list): í…Œì´ë¸” ë°ì´í„° í–‰ ë¦¬ìŠ¤íŠ¸.
    """
    ws = wb.create_sheet(title=sheet_name)
    ws.append(["[ê¸°ë³¸ ì •ë³´]"])
    for key, value in basic_info.items():
        ws.append([key, value])
    ws.append([])
    ws.append([f"[{sheet_name} - ê±°ë˜ ë‚´ì—­]"])
    ws.append(header)
    for row in rows:
        ws.append([replace_W_before_number(cell) for cell in row])

# ì‹¤í–‰
def process_pdf_and_ocr(input_pdf_path, update_progress_callback=None):
    """
    PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  OCRì„ ìˆ˜í–‰í•˜ì—¬ Excel íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Args:
        input_pdf_path (str): ì²˜ë¦¬í•  ì…ë ¥ PDF íŒŒì¼ì˜ ê²½ë¡œ.
        update_progress_callback (function, optional): ì§„í–‰ë¥ ì„ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•œ ì½œë°± í•¨ìˆ˜.
                                                      Defaults to None.

    Returns:
        openpyxl.Workbook: ì²˜ë¦¬ëœ ë°ì´í„°ê°€ í¬í•¨ëœ Excel ì›Œí¬ë¶ ê°ì²´.
    """
    temp_dir = os.path.join('temp_split', os.path.splitext(os.path.basename(input_pdf_path))[0])

    pdf_pages = split_pdf_pages(input_pdf_path, temp_dir)
    total_pages = len(pdf_pages)

    wb = Workbook()
    # ê¸°ë³¸ìœ¼ë¡œ ìƒì„±ëœ ì‹œíŠ¸ ì œê±°
    if 'Sheet' in wb.sheetnames:
        wb.remove(wb['Sheet'])

    for idx, page_pdf in enumerate(pdf_pages):
        print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: í˜ì´ì§€ {idx + 1}/{total_pages}")

        result = call_ocr_api(page_pdf)
        if not result or 'images' not in result:
            print(f"[âš ï¸] í˜ì´ì§€ {idx + 1} OCR ì‹¤íŒ¨ ë˜ëŠ” ì‘ë‹µì— 'images' í‚¤ ì—†ìŒ.")
            if update_progress_callback:
                update_progress_callback((idx + 1) / total_pages * 100)
            continue

        # ëª¨ë“  í•„ë“œë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ìë‹ˆë‹¤.
        all_fields_from_ocr = []
        full_page_text_for_basic_info = ""

        for image_data in result['images']:
            if 'fields' in image_data:
                all_fields_from_ocr.extend(image_data['fields'])
                for field_item in image_data['fields']:
                    full_page_text_for_basic_info += field_item.get('inferText', '') + " "

            if 'title' in image_data and 'subFields' in image_data['title']:
                # title í•„ë“œ ìì²´ë„ all_fields_from_ocrì— í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                # ì—¬ê¸°ì„œëŠ” subFieldsë§Œ ì¶”ì¶œí•˜ì—¬ header_fields_from_subfieldsë¡œ ë„˜ê²¨ì¤„ í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ,
                # ë‹¨ìˆœíˆ full_page_text_for_basic_infoì— ì¶”ê°€í•©ë‹ˆë‹¤.
                full_page_text_for_basic_info += image_data['title'].get('inferText', '') + " "


        # í˜ì´ì§€ ì²˜ë¦¬ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        if update_progress_callback:
            progress = (idx + 1) / total_pages * 100
            update_progress_callback(int(progress))



        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        basic_info = extract_basic_info(full_page_text_for_basic_info)
        print(f'í˜ì´ì§€ {idx+1}ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ì¼ë¶€): {full_page_text_for_basic_info[:200]}...') # ë””ë²„ê¹…ì„ ìœ„í•´ ì²˜ìŒ 200ì ì¸ì‡„

        try:
            # extract_transaction_table_by_position í•¨ìˆ˜ì— ëª¨ë“  í•„ë“œë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
            header, rows = extract_transaction_table_by_position(all_fields_from_ocr)
            save_to_excel(wb, f"í˜ì´ì§€ {idx + 1}", basic_info, header, rows)
            print(f"âœ… í˜ì´ì§€ {idx + 1} ê±°ë˜ ë‚´ì—­ ì¶”ì¶œ ë° Excel ì €ì¥ ì™„ë£Œ.")
        except ValueError as ve:
            print(f"[âŒ] í˜ì´ì§€ {idx + 1} ê±°ë˜ ë‚´ì—­ ì²˜ë¦¬ ì˜¤ë¥˜: {ve}")
        except Exception as e:
            print(f"[âŒ] í˜ì´ì§€ {idx + 1} ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

    return wb
